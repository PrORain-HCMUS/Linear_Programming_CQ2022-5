{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc30b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:34:07.406029Z",
     "iopub.status.busy": "2025-07-13T07:34:07.405791Z",
     "iopub.status.idle": "2025-07-13T07:34:16.073294Z",
     "shell.execute_reply": "2025-07-13T07:34:16.072130Z"
    },
    "papermill": {
     "duration": 8.674355,
     "end_time": "2025-07-13T07:34:16.074751",
     "exception": false,
     "start_time": "2025-07-13T07:34:07.400396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.1/220.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install cvxpy tqdm --quiet\n",
    "!pip install ecos --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a6925",
   "metadata": {
    "papermill": {
     "duration": 0.00398,
     "end_time": "2025-07-13T07:34:16.083371",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.079391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Giới thiệu vấn đề\n",
    "Vấn đề cân bằng xe đạp là một bài toán kinh điển trong học tăng cường (RL), nơi mục tiêu là giữ cho xe đạp cân bằng bằng cách thực hiện các hành động thích hợp (ví dụ: mô-men xoắn lái) để duy trì sự ổn định. Mã Python cung cấp ba phương pháp để giải quyết vấn đề này: Quy hoạch động (DP), Quy hoạch tuyến tính (LP) và Quy hoạch tuyến tính xấp xỉ (ALP). Bài thuyết trình này giới thiệu mã, làm nổi bật các thành phần chính và so sánh hiệu suất của các phương pháp này.\n",
    "\n",
    "Code sẽ phân tách không gian trạng thái, mô hình hóa động lực học của xe đạp, tính toán ma trận chuyển tiếp và phần thưởng, và áp dụng ba phương pháp RL để đưa ra chính sách tối ưu. Dưới đây, chúng ta sẽ đi qua thiết lập vấn đề, các đoạn mã chính và kết quả đánh giá.\n",
    "\n",
    "### Thiết lập vấn đề\n",
    "Vấn đề cân bằng xe đạp liên quan đến việc điều khiển một chiếc xe đạp để giữ thẳng đứng bằng cách điều chỉnh góc lái. Trạng thái của hệ thống được xác định bởi bốn biến:\n",
    "\n",
    "phi: Góc của xe đạp so với phương thẳng đứng (góc nghiêng).\n",
    "phi_dot: Tốc độ góc của nghiêng.\n",
    "delta: Góc lái.\n",
    "delta_dot: Tốc độ góc của góc lái.\n",
    "Không gian hành động bao gồm ba hành động rời rạc: áp dụng mô-men xoắn âm (trái), không có mô-men xoắn (giữa), hoặc mô-men xoắn dương (phải). Mục tiêu là tối đa hóa phần thưởng tích lũy trong khi ngăn xe đạp ngã (tức là giữ phi trong giới hạn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79324cf3",
   "metadata": {
    "papermill": {
     "duration": 0.003941,
     "end_time": "2025-07-13T07:34:16.091215",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.087274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277e9663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:34:16.100037Z",
     "iopub.status.busy": "2025-07-13T07:34:16.099805Z",
     "iopub.status.idle": "2025-07-13T07:34:16.107634Z",
     "shell.execute_reply": "2025-07-13T07:34:16.106755Z"
    },
    "papermill": {
     "duration": 0.013733,
     "end_time": "2025-07-13T07:34:16.108784",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.095051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import time, tracemalloc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f07514",
   "metadata": {
    "papermill": {
     "duration": 0.003648,
     "end_time": "2025-07-13T07:34:16.116335",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.112687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Rời rạc hóa trạng thái\n",
    "Để làm cho vấn đề có thể giải quyết được, không gian trạng thái liên tục được phân tách thành một lưới 12 bin cho mỗi chiều, dẫn đến 20.736 trạng thái (12×12×12×12). Mã định nghĩa các khoảng và phân tách các biến trạng thái như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee5cefd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:34:16.124806Z",
     "iopub.status.busy": "2025-07-13T07:34:16.124538Z",
     "iopub.status.idle": "2025-07-13T07:34:16.187926Z",
     "shell.execute_reply": "2025-07-13T07:34:16.187117Z"
    },
    "papermill": {
     "duration": 0.069094,
     "end_time": "2025-07-13T07:34:16.189239",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.120145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số trạng thái rời rạc: 20736, số hành động: 3\n"
     ]
    }
   ],
   "source": [
    "# Rời rạc hóa mỗi biến thành 9 mức\n",
    "n_bins = 12\n",
    "phi_range = (-0.5, 0.5)\n",
    "phi_dot_range = (-1.0, 1.0)\n",
    "delta_range = (-0.3, 0.3)\n",
    "delta_dot_range = (-1.0, 1.0)\n",
    "\n",
    "phi_vals = np.linspace(*phi_range, n_bins)\n",
    "phi_dot_vals = np.linspace(*phi_dot_range, n_bins)\n",
    "delta_vals = np.linspace(*delta_range, n_bins)\n",
    "delta_dot_vals = np.linspace(*delta_dot_range, n_bins)\n",
    "\n",
    "all_states = list(product(range(n_bins), repeat=4))\n",
    "state_id = {s: i for i, s in enumerate(all_states)}\n",
    "num_states = len(all_states)\n",
    "actions = [-1, 0, 1]  # trái, giữa, phải\n",
    "num_actions = len(actions)\n",
    "\n",
    "print(f\"Số trạng thái rời rạc: {num_states}, số hành động: {num_actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d12a1b",
   "metadata": {
    "papermill": {
     "duration": 0.004188,
     "end_time": "2025-07-13T07:34:16.197984",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.193796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Các thành phần mã chính\n",
    "#### Động lực học xe đạp\n",
    "Hàm bicycle_next_state mô hình hóa động lực học của xe đạp dựa trên các tham số vật lý (trọng lực, chiều dài, lực ma sát) và mô-men xoắn áp dụng. Nó tính toán trạng thái tiếp theo bằng cách sử dụng tích phân Euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070e0cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:34:16.208453Z",
     "iopub.status.busy": "2025-07-13T07:34:16.208227Z",
     "iopub.status.idle": "2025-07-13T07:34:16.213144Z",
     "shell.execute_reply": "2025-07-13T07:34:16.212506Z"
    },
    "papermill": {
     "duration": 0.012341,
     "end_time": "2025-07-13T07:34:16.214474",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.202133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bicycle_next_state(state, action, dt=0.1):\n",
    "    phi, phi_dot, delta, delta_dot = state\n",
    "\n",
    "    g = 9.8\n",
    "    l = 1.0\n",
    "    b = 0.1\n",
    "    max_delta = 0.3\n",
    "\n",
    "    torque = 0.02 * action\n",
    "    phi_ddot = (g / l) * np.sin(phi) + delta_dot\n",
    "    delta_ddot = torque - b * delta_dot - phi\n",
    "\n",
    "    phi_dot += phi_ddot * dt\n",
    "    phi += phi_dot * dt\n",
    "    delta_dot += delta_ddot * dt\n",
    "    delta += delta_dot * dt\n",
    "    delta = np.clip(delta, -max_delta, max_delta)\n",
    "\n",
    "    return np.array([phi, phi_dot, delta, delta_dot])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccf50ca",
   "metadata": {
    "papermill": {
     "duration": 0.003949,
     "end_time": "2025-07-13T07:34:16.222654",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.218705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hàm discretize_state ánh xạ các trạng thái liên tục trở lại lưới rời rạc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74279157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:34:16.232077Z",
     "iopub.status.busy": "2025-07-13T07:34:16.231814Z",
     "iopub.status.idle": "2025-07-13T07:34:16.237088Z",
     "shell.execute_reply": "2025-07-13T07:34:16.236505Z"
    },
    "papermill": {
     "duration": 0.011231,
     "end_time": "2025-07-13T07:34:16.238129",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.226898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discretize_state(state):\n",
    "    phi, phi_dot, delta, delta_dot = state\n",
    "    phi_idx = np.digitize(phi, phi_vals) - 1\n",
    "    phi_dot_idx = np.digitize(phi_dot, phi_dot_vals) - 1\n",
    "    delta_idx = np.digitize(delta, delta_vals) - 1\n",
    "    delta_dot_idx = np.digitize(delta_dot, delta_dot_vals) - 1\n",
    "    return (\n",
    "        np.clip(phi_idx, 0, n_bins - 1),\n",
    "        np.clip(phi_dot_idx, 0, n_bins - 1),\n",
    "        np.clip(delta_idx, 0, n_bins - 1),\n",
    "        np.clip(delta_dot_idx, 0, n_bins - 1),\n",
    "    )\n",
    "\n",
    "def undiscretize_index(idx):\n",
    "    return np.array([\n",
    "        phi_vals[idx[0]],\n",
    "        phi_dot_vals[idx[1]],\n",
    "        delta_vals[idx[2]],\n",
    "        delta_dot_vals[idx[3]]\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd21e4b",
   "metadata": {
    "papermill": {
     "duration": 0.003522,
     "end_time": "2025-07-13T07:34:16.245601",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.242079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Ma trận xác suất chuyển tiếp và phần thưởng\n",
    "Mã xây dựng một ma trận chuyển tiếp $T$ và ma trận phần thưởng $R$. Đối với mỗi cặp trạng thái-hành động, nó tính toán trạng thái tiếp theo và gán một phần thưởng (mặc định: -1, hoặc -100 nếu xe đạp ngã, tức là $|\\phi|$ > 0.5):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b6c465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:34:16.253436Z",
     "iopub.status.busy": "2025-07-13T07:34:16.253255Z",
     "iopub.status.idle": "2025-07-13T07:34:19.008726Z",
     "shell.execute_reply": "2025-07-13T07:34:19.007930Z"
    },
    "papermill": {
     "duration": 2.760905,
     "end_time": "2025-07-13T07:34:19.010122",
     "exception": false,
     "start_time": "2025-07-13T07:34:16.249217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã tính xong T và R.\n"
     ]
    }
   ],
   "source": [
    "T = dict()\n",
    "R = np.full((num_states, num_actions), -1.0)\n",
    "\n",
    "for s_idx, s_tuple in enumerate(all_states):\n",
    "    T[s_idx] = dict()\n",
    "    for a_idx, a in enumerate(actions):\n",
    "        s_continuous = undiscretize_index(s_tuple)\n",
    "        s_next_continuous = bicycle_next_state(s_continuous, a)\n",
    "        s_next_tuple = discretize_state(s_next_continuous)\n",
    "\n",
    "        if abs(s_next_continuous[0]) > 0.5:\n",
    "            R[s_idx, a_idx] = -100.0\n",
    "            s_next_tuple = s_tuple\n",
    "\n",
    "        s_next_idx = state_id.get(s_next_tuple, s_idx)\n",
    "        T[s_idx][a_idx] = [(s_next_idx, 1.0)]\n",
    "\n",
    "print(\"✅ Đã tính xong T và R.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434401c",
   "metadata": {
    "papermill": {
     "duration": 0.003708,
     "end_time": "2025-07-13T07:34:19.017846",
     "exception": false,
     "start_time": "2025-07-13T07:34:19.014138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Thuật toán Quy hoạch động (DP):\n",
    "\n",
    "DP giải quyết MDP bằng cách tính toán lặp đi lặp lại value function $V(s)$ cho từng trạng thái sử dụng phương trình Bellman.\n",
    "\n",
    "Trong code được cung cấp, Giá trị lặp cập nhật hàm giá trị $V(s)$ cho tất cả các trạng thái cho đến khi hội tụ, sau đó rút ra chính sách tối ưu $\\pi(s)$ bằng cách chọn hành động tối đa hóa phần thưởng kỳ vọng cộng với giá trị tương lai đã chiết khấu.  \n",
    "Các bước chính:  \n",
    "+ Khởi tạo $V(s) = 0$ cho tất cả các trạng thái.  \n",
    "+ Cập nhật $V(s) \\leftarrow \\max_a \\left[ R(s,a) + \\gamma \\sum_{s'} P(s'|s,a) V(s') \\right]$ cho đến khi sự thay đổi trong $V(s)$ dưới một ngưỡng.  \n",
    "+ Trích xuất chính sách tham lam: $\\pi(s) = \\arg\\max_a \\left[ R(s,a) + \\gamma \\sum_{s'} P(s'|s,a) V(s') \\right]$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d175f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:34:19.026267Z",
     "iopub.status.busy": "2025-07-13T07:34:19.026070Z",
     "iopub.status.idle": "2025-07-13T07:36:36.728565Z",
     "shell.execute_reply": "2025-07-13T07:36:36.727734Z"
    },
    "papermill": {
     "duration": 137.712146,
     "end_time": "2025-07-13T07:36:36.733788",
     "exception": false,
     "start_time": "2025-07-13T07:34:19.021642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Value Iteration hội tụ sau 226 vòng.\n",
      "⏱️ Thời gian: 137.70s | 💾 Peak memory: 0.36MB\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.95\n",
    "threshold = 1e-3\n",
    "V_dp = np.zeros(num_states)\n",
    "iteration = 0\n",
    "\n",
    "# Bắt đầu đo thời gian và bộ nhớ\n",
    "start = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "while True:\n",
    "    delta = 0\n",
    "    V_new = np.zeros_like(V_dp)\n",
    "    for s in range(num_states):\n",
    "        V_new[s] = max(\n",
    "            R[s, a] + gamma * sum(p * V_dp[s2] for s2, p in T[s][a])\n",
    "            for a in range(num_actions)\n",
    "        )\n",
    "        delta = max(delta, abs(V_new[s] - V_dp[s]))\n",
    "    V_dp = V_new\n",
    "    iteration += 1\n",
    "    if delta < threshold:\n",
    "        break\n",
    "\n",
    "# Tính chính sách greedy từ giá trị V_dp\n",
    "pi_dp = np.zeros(num_states, dtype=int)\n",
    "for s in range(num_states):\n",
    "    pi_dp[s] = int(np.argmax([\n",
    "        R[s, a] + gamma * sum(p * V_dp[s2] for s2, p in T[s][a])\n",
    "        for a in range(num_actions)\n",
    "    ]))\n",
    "\n",
    "# Dừng đo bộ nhớ và thời gian\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Value Iteration hội tụ sau {iteration} vòng.\")\n",
    "print(f\"⏱️ Thời gian: {elapsed:.2f}s | 💾 Peak memory: {peak / 1e6:.2f}MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb5c198",
   "metadata": {
    "papermill": {
     "duration": 0.004094,
     "end_time": "2025-07-13T07:36:36.742221",
     "exception": false,
     "start_time": "2025-07-13T07:36:36.738127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Quy hoạch tuyến tính (LP):\n",
    "LP tái cấu trúc MDP thành một bài toán tối ưu hóa tuyến tính, tối thiểu hóa tổng các giá trị trạng thái $\\sum_s V(s)$ dưới các ràng buộc Bellman.\n",
    "\n",
    "Các ràng buộc đảm bảo rằng hàm giá trị thỏa mãn $V(s) \\geq R(s,a) + \\gamma \\sum_{s'} P(s'|s,a) V(s')$ cho tất cả các trạng thái $s$ và hành động $a$.\n",
    "Giải pháp cung cấp hàm giá trị tối ưu $V(s)$, từ đó chính sách được rút ra một cách tham lam.  \n",
    "Các bước chính:\n",
    "+ Cấu trúc LP với các biến $V(s)$ cho mỗi trạng thái.  \n",
    "+ Thêm các ràng buộc cho mỗi cặp trạng thái-hành động.  \n",
    "Giải quyết bằng cách sử dụng một bộ giải LP (ví dụ: scipy.optimize.linprog với phương pháp \"highs\").  \n",
    "+ Tính toán chính sách bằng cách tối đa hóa hàm giá trị hành động."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c9d0e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:36:36.751327Z",
     "iopub.status.busy": "2025-07-13T07:36:36.751096Z",
     "iopub.status.idle": "2025-07-13T07:37:15.641353Z",
     "shell.execute_reply": "2025-07-13T07:37:15.640564Z"
    },
    "papermill": {
     "duration": 38.897515,
     "end_time": "2025-07-13T07:37:15.643794",
     "exception": false,
     "start_time": "2025-07-13T07:36:36.746279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1363212621.py:27: OptimizeWarning: Unrecognized options detected: {'tol': 1e-09}. These will be passed to HiGHS verbatim.\n",
      "  res_lp = linprog(\n",
      "/usr/local/lib/python3.11/dist-packages/scipy/optimize/_linprog_highs.py:355: OptimizeWarning: Unrecognized options detected: {'tol': 1e-09}\n",
      "  res = _highs_wrapper(c, A.indptr, A.indices, A.data, lhs, rhs,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã giải xong LP (phiên bản tối ưu hóa).\n",
      "⏱️ Thời gian: 37.58s | 💾 Peak memory: 30974.79MB\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "import time, tracemalloc\n",
    "\n",
    "# ⏱️ Bắt đầu đo hiệu suất\n",
    "start = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "# ⚙️ Xây dựng ràng buộc LP: v_s >= R(s,a) + γ * ∑ P(s'|s,a) * v_s'\n",
    "A_ub = []\n",
    "b_ub = []\n",
    "\n",
    "for s in range(num_states):\n",
    "    for a in range(num_actions):\n",
    "        if not T[s][a]:\n",
    "            continue  # Bỏ qua nếu hành động không hợp lệ\n",
    "        row = np.zeros(num_states)\n",
    "        row[s] = -1  # v_s chuyển sang vế trái\n",
    "        for s2, p in T[s][a]:  # T[s][a] là list of (s', p)\n",
    "            row[s2] += gamma * p\n",
    "        A_ub.append(row)\n",
    "        b_ub.append(-R[s, a])  # RHS chuyển dấu sang phải\n",
    "\n",
    "# 🎯 Hàm mục tiêu: minimize ∑ v_s\n",
    "c = np.ones(num_states)\n",
    "\n",
    "# 🧮 Giải bài toán LP\n",
    "res_lp = linprog(\n",
    "    c,\n",
    "    A_ub=A_ub,\n",
    "    b_ub=b_ub,\n",
    "    method=\"highs\",\n",
    "    options={\"tol\": 1e-9}\n",
    ")\n",
    "\n",
    "# 📈 Lấy giá trị trạng thái từ nghiệm tối ưu\n",
    "V_lp = res_lp.x\n",
    "\n",
    "# 🧭 Suy ra chính sách greedy từ giá trị LP\n",
    "pi_lp = np.zeros(num_states, dtype=int)\n",
    "for s in range(num_states):\n",
    "    q_values = [\n",
    "        R[s, a] + gamma * sum(p * V_lp[s2] for s2, p in T[s][a])\n",
    "        if T[s][a] else -np.inf\n",
    "        for a in range(num_actions)\n",
    "    ]\n",
    "    pi_lp[s] = int(np.argmax(q_values))\n",
    "\n",
    "# 🧮 Dừng đo hiệu suất\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"✅ Đã giải xong LP (phiên bản tối ưu hóa).\")\n",
    "print(f\"⏱️ Thời gian: {elapsed:.2f}s | 💾 Peak memory: {peak / 1e6:.2f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637372e",
   "metadata": {
    "papermill": {
     "duration": 0.003813,
     "end_time": "2025-07-13T07:37:15.651879",
     "exception": false,
     "start_time": "2025-07-13T07:37:15.648066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Thuật toán Quy hoạch tuyến tính xấp xỉ (ALP):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee967a",
   "metadata": {
    "papermill": {
     "duration": 0.003785,
     "end_time": "2025-07-13T07:37:15.659510",
     "exception": false,
     "start_time": "2025-07-13T07:37:15.655725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Chọn đặc trưng\n",
    "Hàm đặc trưng phi(s) cho bài toán Bicycle Balancing  \n",
    "Trạng thái s là index, ánh xạ đến tuple (phi, phi_dot, delta, delta_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28a92b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:37:15.668958Z",
     "iopub.status.busy": "2025-07-13T07:37:15.668622Z",
     "iopub.status.idle": "2025-07-13T07:37:15.732407Z",
     "shell.execute_reply": "2025-07-13T07:37:15.731740Z"
    },
    "papermill": {
     "duration": 0.069603,
     "end_time": "2025-07-13T07:37:15.733466",
     "exception": false,
     "start_time": "2025-07-13T07:37:15.663863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features(s):\n",
    "    # Giải mã lại trạng thái từ chỉ số s\n",
    "    phi_idx, phi_dot_idx, delta_idx, delta_dot_idx = all_states[s]\n",
    "\n",
    "    # Chuẩn hóa mỗi thành phần về [0, 1]\n",
    "    phi_norm = phi_idx / (n_bins - 1)\n",
    "    phi_dot_norm = phi_dot_idx / (n_bins - 1)\n",
    "    delta_norm = delta_idx / (n_bins - 1)\n",
    "    delta_dot_norm = delta_dot_idx / (n_bins - 1)\n",
    "\n",
    "    # Trả về vector đặc trưng phi(s)\n",
    "    return np.array([\n",
    "        1.0,\n",
    "        phi_norm,\n",
    "        phi_dot_norm,\n",
    "        delta_norm,\n",
    "        delta_dot_norm,\n",
    "        phi_norm ** 2,\n",
    "        phi_dot_norm ** 2,\n",
    "        delta_norm ** 2,\n",
    "        delta_dot_norm ** 2,\n",
    "        phi_norm * delta_norm,\n",
    "        phi_dot_norm * delta_dot_norm,\n",
    "        phi_norm * delta_dot_norm,\n",
    "        phi_dot_norm * delta_norm,\n",
    "    ])\n",
    "\n",
    "Phi = np.array([get_features(s) for s in range(num_states)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82de375",
   "metadata": {
    "papermill": {
     "duration": 0.003739,
     "end_time": "2025-07-13T07:37:15.741263",
     "exception": false,
     "start_time": "2025-07-13T07:37:15.737524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ALP giải quyết vấn đề khả năng mở rộng của LP bằng cách xấp xỉ hàm giá trị dưới dạng một tổ hợp tuyến tính của các đặc trưng: $V(s) \\approx \\phi(s)^T \\theta$, trong đó $\\phi(s)$ là một vector đặc trưng cho trạng thái $s$, và $\\theta$ là một vector tham số.  \n",
    "Thay vì tối ưu hóa trên tất cả các trạng thái, ALP tối ưu hóa trên không gian đặc trưng, giảm số lượng biến từ $|S|$ xuống kích thước đặc trưng $|\\phi|$.  \n",
    "LP tối thiểu hóa $\\sum |\\theta|$ (hoặc một mục tiêu liên quan) dưới các ràng buộc đảm bảo rằng hàm giá trị xấp xỉ thỏa mãn bất đẳng thức Bellman.  \n",
    "Các bước chính:  \n",
    "+ Định nghĩa một ma trận đặc trưng $\\Phi$ trong đó mỗi hàng là $\\phi(s)$.  \n",
    "+ Cấu trúc các ràng buộc: $\\phi(s)^T \\theta \\geq R(s,a) + \\gamma \\sum_{s'} P(s'|s,a) \\phi(s')^T \\theta$.  \n",
    "+ Giải cho $\\theta$, tính toán $V(s) = \\phi(s)^T \\theta$, và rút ra chính sách một cách tham lam.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe9b134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:37:15.749964Z",
     "iopub.status.busy": "2025-07-13T07:37:15.749747Z",
     "iopub.status.idle": "2025-07-13T07:37:43.846415Z",
     "shell.execute_reply": "2025-07-13T07:37:43.845495Z"
    },
    "papermill": {
     "duration": 28.102727,
     "end_time": "2025-07-13T07:37:43.847842",
     "exception": false,
     "start_time": "2025-07-13T07:37:15.745115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã giải xong ALP (phiên bản chuẩn LP dùng linprog).\n",
      "⏱️ Thời gian: 28.09s | 💾 Peak memory: 77.83MB\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "from scipy.sparse import lil_matrix\n",
    "import time, tracemalloc\n",
    "\n",
    "# Bắt đầu đo hiệu suất\n",
    "start = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "phi_dim = Phi.shape[1]  # Số chiều đặc trưng\n",
    "\n",
    "# 🔧 Xây dựng ràng buộc dưới dạng A_ub @ theta <= b_ub\n",
    "num_constraints = sum(len(T[s][a]) > 0 for s in range(num_states) for a in range(num_actions))\n",
    "A_ub = lil_matrix((num_constraints, phi_dim))  # sparse matrix\n",
    "b_ub = []\n",
    "\n",
    "row_idx = 0\n",
    "for s in range(num_states):\n",
    "    phi_s = Phi[s]\n",
    "    for a in range(num_actions):\n",
    "        if not T[s][a]: continue  # skip nếu hành động không hợp lệ\n",
    "        expected_phi = np.zeros(phi_dim)\n",
    "        for s2, p in T[s][a]:\n",
    "            expected_phi += p * Phi[s2]\n",
    "        A_ub[row_idx, :] = expected_phi * gamma - phi_s  # chuyển vế\n",
    "        b_ub.append(-R[s, a])  # RHS\n",
    "        row_idx += 1\n",
    "\n",
    "# 🎯 Hàm mục tiêu: minimize ∑|theta| ≈ minimize ∑ theta (với ràng buộc phù hợp)\n",
    "# Ở đây ta minimize ∑ theta để tương ứng với chuẩn L1 (theta >= 0 sẽ đảm bảo tương đương)\n",
    "c = np.ones(phi_dim)\n",
    "\n",
    "# 🧮 Giải bài toán LP với solver \"highs\"\n",
    "res = linprog(\n",
    "    c,\n",
    "    A_ub=A_ub,\n",
    "    b_ub=b_ub,\n",
    "    method=\"highs\"\n",
    ")\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "if not res.success:\n",
    "    raise ValueError(\"Không giải được bài toán ALP bằng linprog:\", res.message)\n",
    "\n",
    "theta_opt = res.x\n",
    "V_alp = Phi @ theta_opt\n",
    "\n",
    "# 🧭 Suy ra chính sách greedy từ V_alp\n",
    "pi_alp = np.zeros(num_states, dtype=int)\n",
    "for s in range(num_states):\n",
    "    q_vals = []\n",
    "    for a in range(num_actions):\n",
    "        expected = sum(p * V_alp[s2] for s2, p in T[s][a])\n",
    "        q_vals.append(R[s, a] + gamma * expected)\n",
    "    pi_alp[s] = int(np.argmax(q_vals))\n",
    "\n",
    "# 🧮 Dừng đo hiệu suất\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"✅ Đã giải xong ALP (phiên bản chuẩn LP dùng linprog).\")\n",
    "print(f\"⏱️ Thời gian: {elapsed:.2f}s | 💾 Peak memory: {peak / 1e6:.2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e56104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:37:43.860255Z",
     "iopub.status.busy": "2025-07-13T07:37:43.860026Z",
     "iopub.status.idle": "2025-07-13T07:37:48.012291Z",
     "shell.execute_reply": "2025-07-13T07:37:48.011380Z"
    },
    "papermill": {
     "duration": 4.158938,
     "end_time": "2025-07-13T07:37:48.013773",
     "exception": false,
     "start_time": "2025-07-13T07:37:43.854835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã giải xong ALP (sampling).\n",
      "⏱️ Thời gian: 4.00s | 💾 Peak memory: 9.40MB\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "from scipy.sparse import lil_matrix\n",
    "import time, tracemalloc\n",
    "\n",
    "# === Sampling-Based ALP ===\n",
    "\n",
    "# ⚙️ Sampling trạng thái theo occupancy từ chính sách ban đầu (VD: random)\n",
    "sampled_states = []\n",
    "num_samples = 7500\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    s = np.random.choice(num_states)\n",
    "    a = np.random.choice(num_actions)\n",
    "    if T[s][a]:  # chỉ chọn (s, a) hợp lệ\n",
    "        sampled_states.append((s, a))\n",
    "\n",
    "# Bắt đầu đo hiệu suất\n",
    "start = time.time()\n",
    "tracemalloc.start()\n",
    "c\n",
    "phi_dim = Phi.shape[1]\n",
    "A_ub = lil_matrix((len(sampled_states), phi_dim))\n",
    "b_ub = []\n",
    "\n",
    "for idx, (s, a) in enumerate(sampled_states):\n",
    "    phi_s = Phi[s]\n",
    "    expected_phi = np.zeros(phi_dim)\n",
    "    for s2, p in T[s][a]:\n",
    "        expected_phi += p * Phi[s2]\n",
    "    A_ub[idx, :] = expected_phi * gamma - phi_s\n",
    "    b_ub.append(-R[s, a])\n",
    "\n",
    "# 🎯 Hàm mục tiêu: minimize ∑ θ\n",
    "c = np.ones(phi_dim)\n",
    "\n",
    "# 🧮 Giải ALP (sampling version)\n",
    "res = linprog(\n",
    "    c,\n",
    "    A_ub=A_ub,\n",
    "    b_ub=b_ub,\n",
    "    method=\"highs\"\n",
    ")\n",
    "\n",
    "if not res.success:\n",
    "    raise ValueError(\"Không giải được ALP (sampling):\", res.message)\n",
    "\n",
    "theta_opt_sampled = res.x\n",
    "V_alp_sampled = Phi @ theta_opt_sampled\n",
    "\n",
    "# 🧭 Suy ra chính sách greedy từ ALP sampling\n",
    "pi_alp_sampled = np.zeros(num_states, dtype=int)\n",
    "for s in range(num_states):\n",
    "    q_vals = []\n",
    "    for a in range(num_actions):\n",
    "        expected = sum(p * V_alp_sampled[s2] for s2, p in T[s][a])\n",
    "        q_vals.append(R[s, a] + gamma * expected)\n",
    "    pi_alp_sampled[s] = int(np.argmax(q_vals))\n",
    "\n",
    "# Hiệu suất\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"✅ Đã giải xong ALP (sampling).\")\n",
    "print(f\"⏱️ Thời gian: {elapsed:.2f}s | 💾 Peak memory: {peak / 1e6:.2f}MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d28a4a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:37:48.024454Z",
     "iopub.status.busy": "2025-07-13T07:37:48.024233Z",
     "iopub.status.idle": "2025-07-13T07:37:51.961828Z",
     "shell.execute_reply": "2025-07-13T07:37:51.960798Z"
    },
    "papermill": {
     "duration": 3.944569,
     "end_time": "2025-07-13T07:37:51.963145",
     "exception": false,
     "start_time": "2025-07-13T07:37:48.018576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã giải xong ALP (prioritized sampling).\n",
      "⏱️ Thời gian: 3.79s | 💾 Peak memory: 9.40MB\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "from scipy.sparse import lil_matrix\n",
    "import time, tracemalloc\n",
    "\n",
    "# === ALP with Prioritized Sampling ===\n",
    "\n",
    "# ⚙️ Bước 1: Tính Bellman error từ V gần đúng (VD: dùng V_dp)\n",
    "errors = []\n",
    "pairs = []\n",
    "for s in range(num_states):\n",
    "    for a in range(num_actions):\n",
    "        if not T[s][a]: continue\n",
    "        expected = sum(p * V_dp[s2] for s2, p in T[s][a])\n",
    "        error = abs(V_dp[s] - (R[s, a] + gamma * expected))\n",
    "        errors.append(error)\n",
    "        pairs.append((s, a))\n",
    "\n",
    "# ⚖️ Bước 2: Chuẩn hóa lỗi thành phân phối xác suất\n",
    "errors = np.array(errors)\n",
    "probs = errors + 1e-6  # tránh 0\n",
    "probs /= probs.sum()\n",
    "\n",
    "# 🎲 Bước 3: Sampling theo Bellman error\n",
    "num_samples = 7500\n",
    "np.random.seed(42)\n",
    "sampled_indices = np.random.choice(len(pairs), size=num_samples, replace=False, p=probs)\n",
    "sampled_states = [pairs[i] for i in sampled_indices]\n",
    "\n",
    "# 🚀 Bắt đầu giải ALP\n",
    "start = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "phi_dim = Phi.shape[1]\n",
    "A_ub = lil_matrix((num_samples, phi_dim))\n",
    "b_ub = []\n",
    "\n",
    "for idx, (s, a) in enumerate(sampled_states):\n",
    "    phi_s = Phi[s]\n",
    "    expected_phi = np.zeros(phi_dim)\n",
    "    for s2, p in T[s][a]:\n",
    "        expected_phi += p * Phi[s2]\n",
    "    A_ub[idx, :] = expected_phi * gamma - phi_s\n",
    "    b_ub.append(-R[s, a])\n",
    "\n",
    "# 🎯 Hàm mục tiêu: minimize ∑ θ\n",
    "c = np.ones(phi_dim)\n",
    "\n",
    "# 🧮 Giải ALP với prioritized sampling\n",
    "res = linprog(\n",
    "    c,\n",
    "    A_ub=A_ub,\n",
    "    b_ub=b_ub,\n",
    "    method=\"highs\"\n",
    ")\n",
    "\n",
    "if not res.success:\n",
    "    raise ValueError(\"Không giải được ALP (prioritized):\", res.message)\n",
    "\n",
    "theta_opt_prioritized = res.x\n",
    "V_alp_prioritized = Phi @ theta_opt_prioritized\n",
    "\n",
    "# 🧭 Suy ra chính sách greedy từ ALP prioritized\n",
    "pi_alp_prioritized = np.zeros(num_states, dtype=int)\n",
    "for s in range(num_states):\n",
    "    q_vals = []\n",
    "    for a in range(num_actions):\n",
    "        expected = sum(p * V_alp_prioritized[s2] for s2, p in T[s][a])\n",
    "        q_vals.append(R[s, a] + gamma * expected)\n",
    "    pi_alp_prioritized[s] = int(np.argmax(q_vals))\n",
    "\n",
    "# ⏱️ Hiệu suất\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"✅ Đã giải xong ALP (prioritized sampling).\")\n",
    "print(f\"⏱️ Thời gian: {elapsed:.2f}s | 💾 Peak memory: {peak / 1e6:.2f}MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b8333",
   "metadata": {
    "papermill": {
     "duration": 0.004787,
     "end_time": "2025-07-13T07:37:51.973127",
     "exception": false,
     "start_time": "2025-07-13T07:37:51.968340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Kết quả:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c85fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T07:37:51.984040Z",
     "iopub.status.busy": "2025-07-13T07:37:51.983806Z",
     "iopub.status.idle": "2025-07-13T07:37:52.403866Z",
     "shell.execute_reply": "2025-07-13T07:37:52.402838Z"
    },
    "papermill": {
     "duration": 0.42713,
     "end_time": "2025-07-13T07:37:52.405226",
     "exception": false,
     "start_time": "2025-07-13T07:37:51.978096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Reward trung bình mỗi chính sách:\n",
      "  - DP   : -8773.2910\n",
      "  - LP   : -9167.7070\n",
      "  - ALP  : -9158.8960\n",
      "  - ALP (sampling): -9171.3700\n",
      "  - ALP (prioritized sampling): -9078.9040\n",
      "\n",
      "📏 Sai số giá trị trạng thái so với DP:\n",
      "  - LP   : max = 1999.9815, mean = 1565.1108\n",
      "  - ALP  : max = 1999.9815, mean = 1565.1108\n",
      "  - ALP (sampling): max = 1999.9815, mean = 1565.1108\n",
      "\n",
      "🧭 Số trạng thái có chính sách khác với DP:\n",
      "  - LP   : 204 / 20736\n",
      "  - ALP  : 204 / 20736\n",
      "  - ALP (sampling): 204 / 20736\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Hàm đánh giá reward trung bình của một chính sách\n",
    "def evaluate_policy(pi, episodes=1000):\n",
    "    rewards = []\n",
    "    for _ in range(episodes):\n",
    "        s = np.random.choice(num_states)\n",
    "        total_reward = 0\n",
    "        for _ in range(100):\n",
    "            a = pi[s]\n",
    "            if not T[s][a]:  # tránh lỗi khi hành động không hợp lệ\n",
    "                break\n",
    "            next_s, prob = T[s][a][0]\n",
    "            total_reward += R[s, a]\n",
    "            s = next_s\n",
    "        rewards.append(total_reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "# 🎯 Reward trung bình\n",
    "r_dp  = evaluate_policy(pi_dp)\n",
    "r_lp  = evaluate_policy(pi_lp)\n",
    "r_alp = evaluate_policy(pi_alp)\n",
    "r_alp_sampled = evaluate_policy(pi_alp_sampled)\n",
    "r_alp_prioritized_sampled = evaluate_policy(pi_alp_prioritized)\n",
    "\n",
    "# 📏 Sai số giữa V_DP và các V khác\n",
    "max_err_lp  = np.max(np.abs(V_dp - V_lp))\n",
    "mean_err_lp = np.mean(np.abs(V_dp - V_lp))\n",
    "\n",
    "max_err_alp  = np.max(np.abs(V_dp - V_alp))\n",
    "mean_err_alp = np.mean(np.abs(V_dp - V_alp))\n",
    "\n",
    "max_err_sampled  = np.max(np.abs(V_dp - V_alp_sampled))\n",
    "mean_err_sampled = np.mean(np.abs(V_dp - V_alp_sampled))\n",
    "\n",
    "# 🧭 So sánh chính sách\n",
    "policy_diff_lp  = np.sum(pi_dp != pi_lp)\n",
    "policy_diff_alp = np.sum(pi_dp != pi_alp)\n",
    "policy_diff_sampled = np.sum(pi_dp != pi_alp_sampled)\n",
    "policy_diff_prioritized_sampled = np.sum(pi_dp!= pi_alp_prioritized)\n",
    "\n",
    "# 📊 In kết quả\n",
    "print(\"🎯 Reward trung bình mỗi chính sách:\")\n",
    "print(f\"  - DP   : {r_dp:.4f}\")\n",
    "print(f\"  - LP   : {r_lp:.4f}\")\n",
    "print(f\"  - ALP  : {r_alp:.4f}\")\n",
    "print(f\"  - ALP (sampling): {r_alp_sampled:.4f}\")\n",
    "print(f\"  - ALP (prioritized sampling): {r_alp_prioritized_sampled:.4f}\\n\")\n",
    "\n",
    "print(\"📏 Sai số giá trị trạng thái so với DP:\")\n",
    "print(f\"  - LP   : max = {max_err_lp:.4f}, mean = {mean_err_lp:.4f}\")\n",
    "print(f\"  - ALP  : max = {max_err_alp:.4f}, mean = {mean_err_alp:.4f}\")\n",
    "print(f\"  - ALP (sampling): max = {max_err_sampled:.4f}, mean = {mean_err_sampled:.4f}\\n\")\n",
    "\n",
    "print(\"🧭 Số trạng thái có chính sách khác với DP:\")\n",
    "print(f\"  - LP   : {policy_diff_lp} / {num_states}\")\n",
    "print(f\"  - ALP  : {policy_diff_alp} / {num_states}\")\n",
    "print(f\"  - ALP (sampling): {policy_diff_sampled} / {num_states}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 231.928585,
   "end_time": "2025-07-13T07:37:53.629784",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-13T07:34:01.701199",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
